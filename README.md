# Snowbird Destinations Analysis

### End-to-End Data Case: from ETL to Dashboard Development.

<img src="0_images/github_cover.png" width="1000">

## 1. Abstract

This Case was proposed by [LeadSimple](https://leadsimple.com/) in its selection process for the vacancy of Product Data Analyst. Its main objective is to verify the candidate's proficiency in tools such as: Python, SQL, Data Visualization, and Cloud Computing.

For this, an end-to-end data project was developed to present data-driven recommendations on the top 3 places a couple and three children could go during the winter months and how long they should stay there.

The project was developed using the data stack below. I used Python scripts to carry out the ETL process, applied SQL in a Data Warehouse on Redshift, performed data modeling, and finally developed the dashboard using Power BI and its native language, DAX.

<div align="center">
    <img src="0_images/data_stack.png" width="500">
</div>

The Dashboard: 
<div align="center">
    <img src="0_images/data_stack.png" width="500">
</div>

## 2. Methodology

The CRISP-DM framework was the guide for this data project development. 

CRISP-DM, which stands for Cross-Industry Standard Process for Data Mining, is an industry-proven way to guide your data mining efforts and it includes descriptions of the typical phases of a project, the tasks involved with each phase, and an explanation of the relationships between these tasks.

<div align="center">
     <img src="0_images/crisp_process.jpg" width="500">
</div>

**Source:* [IBM Docs](https://www.ibm.com/docs/en/spss-modeler/18.2.0?topic=dm-crisp-help-overview)

To direct your reading, below are links to the development carried out at each stage of the CRISP cycle:

* [Business Understanding](https://github.com/vitorhmf/irish-sea#3-business-understanding)
* [Data Understanding](https://github.com/vitorhmf/irish-sea#4-data-understanding)
* [Data Preparation](https://github.com/vitorhmf/irish-sea#5-data-preparation)
* [Machine Learning Modeling](https://github.com/vitorhmf/irish-sea#6-machine-learning-modeling)
* [Evaluation](https://github.com/vitorhmf/irish-sea#7-evaluation)
* [Depoyment](https://github.com/vitorhmf/irish-sea#8-deployment)

## 3. Business Understanding

### 3.1. Context

<img src="0_images/mind_map_business_understanding.png" width="1000">


### 3.2. Business assumption:

[Back to the top](https://github.com/vitorhmf/loyalty-program#2-methodology)

## 4. Data Understanding

### 4.1. Data Cleaning

[Back to the top](https://github.com/vitorhmf/loyalty-program#2-methodology)



## 5. Data Preparation - ETL Process

ETL stands for Extract, Transform, Load. It is a process used in database usage and data warehousing. The ETL process involves extracting data from various sources, transforming the data into a suitable format, and then loading it into a target database or data warehouse for analysis or reporting. This process is critical for data integration and helps in consolidating, cleaning, and organizing data from multiple sources.

### 5.1 Extract:

### 5.2 Transform:

### 5.3 Load:

[Back to the top](https://github.com/vitorhmf/loyalty-program#2-methodology)

## 6. Data Modeling 

### 6.1 Metrics

<img src="0_images/mind_map_score.png" width="1000">

## 7. Evaluation

## 8. Deployment

## 9. Conclusion

### 9.1. Business Results

### 9.2. Next Steps

* Do tests with the embedding spaces in multiple dimensions.

[Back to the top](https://github.com/vitorhmf/loyalty-program#2-methodology)

## 10. References

* [CRISP-DM (IBM Docs)](https://www.ibm.com/docs/en/spss-modeler/18.2.0?topic=dm-crisp-help-overview)
* [Kaggle](https://www.kaggle.com/datasets/carrie1/ecommerce-data)
* [Comunidade DS](https://www.comunidadedatascience.com/)
* [Silhouett Score (Wikipedia)](https://en.wikipedia.org/wiki/Silhouette_(clustering))
* [Running Metabase on AWS](https://www.metabase.com/docs/latest/installation-and-operation/running-metabase-on-elastic-beanstalk)

[Back to the top](https://github.com/vitorhmf/loyalty-program#2-methodology)
